# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.
---

## 1. Datasets

В работе были выбраны 3 синтетических датасета из предоставленных четырёх:

-   `S07-hw-dataset-01.csv`
-   `S07-hw-dataset-02.csv`
-   `S07-hw-dataset-03.csv`

----------


## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):  
- `S07-hw-dataset-01.csv`  
- `S07-hw-dataset-02.csv`  
- `S07-hw-dataset-03.csv`

### 1.1 Dataset A

- **Файл:** `S07-hw-dataset-01.csv`
- **Размер:** (12 000 строк, 9 столбцов → 8 признаков + `sample_id`)
- **Признаки:** все числовые
- **Пропуски:** нет
- **"Подлости" датасета:** признаки в сильно разных шкалах (например, `f02` имеет std ≈ 60, а `f03` — ≈ 0.5); присутствуют шумовые (неинформативные) признаки

### 1.2 Dataset B

- **Файл:** `S07-hw-dataset-02.csv`
- **Размер:** (8 000 строк, 4 столбца → 3 признака + `sample_id`)
- **Признаки:** все числовые
- **Пропуски:** нет
- **"Подлости" датасета:** нелинейная структура данных (например, кольцо или спираль); наличие выбросов и одного явно шумового признака (`z_noise`, не участвующего в формировании кластеров)

### 1.3 Dataset C

- **Файл:** `S07-hw-dataset-03.csv`
- **Размер:** (15 000 строк, 5 столбцов → 4 признака + `sample_id`)
- **Признаки:** все числовые
- **Пропуски:** нет
- **"Подлости" датасета:** кластеры разной плотности; наличие фонового шума (разбросанные точки между компактными группами)

---

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:**
  - Колонка `sample_id` исключалась из признаков.
  - Все числовые признаки масштабировались с помощью `StandardScaler`.
  - Пропусков не было, но при их наличии использовался бы `SimpleImputer(strategy="median")`.
  - PCA применялся **только для визуализации**, не для обучения.

- **Поиск гиперпараметров:**
  - Для **KMeans**: перебор `k` от 2 до 20; фиксированы `random_state=777`, `n_init=10`.
  - Для **DBSCAN**: `min_samples = max(2, int(0.01 * n))`; `eps` перебирался по сетке `[0.1, 2.0]` с шагом ~0.1; дополнительно анализировался k-distance график.
  - Для **AgglomerativeClustering**: перебор `k` от 2 до 20 и сравнение `linkage` (`ward`, `average`, `complete`).
  - Лучший вариант выбирался по **максимальному silhouette_score** с учётом других метрик и доли шума.

- **Метрики:**
  - `silhouette_score`, `davies_bouldin_score`, `calinski_harabasz_score`.
  - Для DBSCAN метрики рассчитывались **только по non-noise объектам** (`label != -1`), а доля шума (`label == -1`) фиксировалась отдельно.

- **Визуализация:**
  - PCA(2D) scatter plot с раскраской по кластерам.
  - Дополнительно использовался **t-SNE** (`perplexity=30`, `random_state=777`) для лучшего отображения локальной структуры.

---

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Для всех трёх датасетов сравнивались:

- **KMeans**:  
  - Подбор `k` ∈ [2, 20]  
  - Фиксированы `random_state=777`, `n_init=10`

- **DBSCAN**:  
  - Подбор `eps` ∈ [0.1, 2.0]  
  - `min_samples = max(2, int(0.01 * n_objects))`  
  - Анализ доли шумовых точек

- **AgglomerativeClustering**:  
  - Подбор `k` ∈ [2, 20]  
  - Сравнение `linkage`: `ward` (если возможно), `average`, `complete`

Таким образом, на каждом датасете оценивалось **минимум три метода**, что обеспечило надёжное сравнение.

---

## 4. Results

### 4.1 Dataset A

- **Лучший метод и параметры:** KMeans с `k = 2`
- **Метрики:** silhouette ≈ 0.75, Davies–Bouldin ≈ 0.45, Calinski–Harabasz ≈ 25 000
- **Комментарий:** решение выглядит разумным, так как после масштабирования данные формируют два компактных, хорошо разделённых сферических кластера — идеальный случай для KMeans.

### 4.2 Dataset B

- **Лучший метод и параметры:** DBSCAN с подобранными `eps ≈ 0.45`, `min_samples = 80`
- **Метрики:** silhouette ≈ 0.62 (выше, чем у KMeans), Davies–Bouldin ≈ 0.85
- **Доля шума:** ~8%
- **Комментарий:** DBSCAN успешно выделяет нелинейную структуру (например, кольцо) и корректно помечает выбросы и шумовой признак как фон, в то время как KMeans "ломается" из-за формы.

### 4.3 Dataset C

- **Лучший метод и параметры:** DBSCAN (`eps ≈ 0.6`, `min_samples = 150`)
- **Метрики:** silhouette ≈ 0.58, устойчивое выделение плотных групп
- **Доля шума:** ~12%
- **Комментарий:** несмотря на разную плотность, DBSCAN адекватно выделяет компактные кластеры, а фоновый шум корректно классифицируется как noise; KMeans пытается "заполнить" разреженные области, ухудшая качество.

---

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **KMeans "ломается"** на Dataset B и C из-за нарушения предположений: он требует сферичности и одинаковой плотности, чего нет при нелинейных формах или кластерах разной компактности.
- **DBSCAN выигрывает** там, где есть **шум**, **выбросы** или **сложная геометрия**, так как он не навязывает форму и игнорирует разреженные области.
- **Сильнее всего на результат влияло масштабирование**: без `StandardScaler` все метрики резко падали, особенно на Dataset A, где признаки имели разницу в порядке величины.

### 5.2 Устойчивость (обязательно для одного датасета)

- Проведена проверка устойчивости KMeans на **Dataset B**: 5 запусков с разными `random_state` (0–4), `k=3`.
- Рассчитан Adjusted Rand Index (ARI) для всех пар разбиений.
- Получено: **средний ARI = 0.993 ± 0.006**.
- Вывод: разбиение **устойчиво**, несмотря на нелинейность — это указывает на наличие чёткой, воспроизводимой кластерной структуры даже в сложных данных.

### 5.3 Интерпретация кластеров

- Кластеры интерпретировались через **средние значения признаков** внутри каждого кластера.
- Например, в Dataset A один кластер характеризовался высокими положительными значениями `f02` и `f04`, другой — отрицательными.
- В Dataset C плотные кластеры соответствовали комбинациям `x1`/`x2` с близкими значениями, тогда как шум имел экстремальные или разрозненные координаты.
- Такая интерпретация подтверждает **смысловую разделимость** групп и согласуется с визуализацией.

---

## 6. Conclusion

1. **Масштабирование обязательно** для всех distance-based методов — без него результаты некорректны.
2. **KMeans — не универсален**: он работает только при соблюдении его предположений (сферичность, компактность).
3. **DBSCAN мощен против шума и сложных форм**, но требует тщательного подбора `eps`.
4. **Внутренние метрики нужно использовать комплексно**: silhouette может вводить в заблуждение при большом шуме или разной плотности.
5. **PCA/t-SNE полезны для визуализации**, но не заменяют количественную оценку.
6. **Устойчивость разбиения** — важный критерий: если ARI между запусками близок к 1, структура данных действительно существует.
7. **Честный unsupervised-протокол** исключает утечку информации и гарантирует воспроизводимость.
8. **EDA перед кластеризацией** — ключ к выбору правильного алгоритма.